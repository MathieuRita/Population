{"sender_default": {"sender": 1, "receiver": 0, "sender_params": {"sender_type": "recurrent", "sender_cell": "LSTM", "sender_num_layers": 1, "sender_hidden_size": 128, "sender_embed_dim": 128}, "sender_optim_params": {"optimizer": "adam", "loss": "REINFORCE", "reward": "referential_log", "baseline": "normalization_batch", "p_step": 0.1, "lr": 0.0005, "entropy_reg_coef": 0.005}, "dataset": {"distribution": "uniform"}}, "sender_default_reco": {"sender": 1, "receiver": 0, "sender_params": {"sender_type": "recurrent", "sender_cell": "LSTM", "sender_num_layers": 1, "sender_hidden_size": 128, "sender_embed_dim": 128}, "sender_optim_params": {"optimizer": "adam", "loss": "REINFORCE", "reward": "log", "baseline": "normalization_batch", "p_step": 1, "lr": 0.0005, "entropy_reg_coef": 0.005}, "dataset": {"distribution": "uniform"}}, "receiver_default": {"sender": 0, "receiver": 1, "receiver_params": {"receiver_type": "recurrent", "receiver_cell": "LSTM", "receiver_num_layers": 1, "receiver_hidden_size": 128, "receiver_embed_dim": 128}, "receiver_optim_params": {"optimizer": "adam", "loss": "referential_loss", "p_step": 1, "lr": 0.0005}, "dataset": {"distribution": "uniform"}}, "receiver_default_reco": {"sender": 0, "receiver": 1, "receiver_params": {"receiver_type": "recurrent", "receiver_cell": "LSTM", "receiver_num_layers": 1, "receiver_hidden_size": 128, "receiver_embed_dim": 128}, "receiver_optim_params": {"optimizer": "adam", "loss": "cross_entropy", "p_step": 1, "lr": 0.0005}, "dataset": {"distribution": "uniform"}}, "sender_default_A": {"sender": 1, "receiver": 0, "sender_params": {"sender_type": "recurrent", "sender_cell": "LSTM", "sender_num_layers": 1, "sender_hidden_size": 128, "sender_embed_dim": 128}, "sender_optim_params": {"optimizer": "adam", "loss": "REINFORCE", "reward": "log", "baseline": "normalization_batch", "p_step": 1, "lr": 0.0005, "entropy_reg_coef": 0.005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_encoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/sender_default_reco_object_encoder.pt", "sender": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/sender_default_reco_sender.pt"}}, "receiver_default_B": {"sender": 0, "receiver": 1, "receiver_params": {"receiver_type": "recurrent", "receiver_cell": "LSTM", "receiver_num_layers": 1, "receiver_hidden_size": 128, "receiver_embed_dim": 128}, "receiver_optim_params": {"optimizer": "adam", "loss": "cross_entropy", "p_step": 0.01, "lr": 0.0005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_decoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/receiver_default_reco_object_decoder.pt", "receiver": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/receiver_default_reco_receiver.pt"}}, "sender_default_B": {"sender": 1, "receiver": 0, "sender_params": {"sender_type": "recurrent", "sender_cell": "LSTM", "sender_num_layers": 1, "sender_hidden_size": 128, "sender_embed_dim": 128}, "sender_optim_params": {"optimizer": "adam", "loss": "REINFORCE", "reward": "log", "baseline": "normalization_batch", "p_step": 1, "lr": 0.0005, "entropy_reg_coef": 0.005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_encoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/sender_default_reco_object_encoder.pt", "sender": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/sender_default_reco_sender.pt"}}, "sender_pivot_A": {"sender": 1, "receiver": 0, "sender_params": {"sender_type": "recurrent", "sender_cell": "LSTM", "sender_num_layers": 1, "sender_hidden_size": 128, "sender_embed_dim": 128}, "sender_optim_params": {"optimizer": "adam", "loss": "REINFORCE", "reward": "log", "baseline": "normalization_batch", "p_step": 1, "lr": 0.0005, "entropy_reg_coef": 0.005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_encoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/sender_default_reco_object_encoder.pt", "sender": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/sender_default_reco_sender.pt"}}, "receiver_default_A": {"sender": 0, "receiver": 1, "receiver_params": {"receiver_type": "recurrent", "receiver_cell": "LSTM", "receiver_num_layers": 1, "receiver_hidden_size": 128, "receiver_embed_dim": 128}, "receiver_optim_params": {"optimizer": "adam", "loss": "cross_entropy", "p_step": 1, "lr": 0.0005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_decoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/receiver_default_reco_object_decoder.pt", "receiver": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/receiver_default_reco_receiver.pt"}}, "receiver_pivot_B": {"sender": 0, "receiver": 1, "receiver_params": {"receiver_type": "recurrent", "receiver_cell": "LSTM", "receiver_num_layers": 1, "receiver_hidden_size": 128, "receiver_embed_dim": 128}, "receiver_optim_params": {"optimizer": "adam", "loss": "cross_entropy", "p_step": 1, "lr": 0.0005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_decoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/receiver_default_reco_object_decoder.pt", "receiver": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/receiver_default_reco_receiver.pt"}}, "sender_A": {"sender": 1, "receiver": 0, "sender_params": {"sender_type": "recurrent", "sender_cell": "LSTM", "sender_num_layers": 1, "sender_hidden_size": 128, "sender_embed_dim": 128}, "sender_optim_params": {"optimizer": "adam", "loss": "REINFORCE", "reward": "log", "baseline": "normalization_batch", "p_step": 1, "lr": 0.0005, "entropy_reg_coef": 0.005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_encoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/sender_default_reco_object_encoder.pt", "sender": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/sender_default_reco_sender.pt"}}, "sender_A_0": {"sender": 1, "receiver": 0, "sender_params": {"sender_type": "recurrent", "sender_cell": "LSTM", "sender_num_layers": 1, "sender_hidden_size": 128, "sender_embed_dim": 128}, "sender_optim_params": {"optimizer": "adam", "loss": "REINFORCE", "reward": "log", "baseline": "normalization_batch", "p_step": 1, "lr": 0.0005, "entropy_reg_coef": 0.005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_encoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/sender_default_reco_object_encoder.pt", "sender": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/sender_default_reco_sender.pt"}}, "receiver_B": {"sender": 0, "receiver": 1, "receiver_params": {"receiver_type": "recurrent", "receiver_cell": "LSTM", "receiver_num_layers": 1, "receiver_hidden_size": 128, "receiver_embed_dim": 128}, "receiver_optim_params": {"optimizer": "adam", "loss": "cross_entropy", "p_step": 0.01, "lr": 0.0005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_decoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/receiver_default_reco_object_decoder.pt", "receiver": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/receiver_default_reco_receiver.pt"}}, "receiver_B_0": {"sender": 0, "receiver": 1, "receiver_params": {"receiver_type": "recurrent", "receiver_cell": "LSTM", "receiver_num_layers": 1, "receiver_hidden_size": 128, "receiver_embed_dim": 128}, "receiver_optim_params": {"optimizer": "adam", "loss": "cross_entropy", "p_step": 0.01, "lr": 0.0005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_decoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/receiver_default_reco_object_decoder.pt", "receiver": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/receiver_default_reco_receiver.pt"}}, "receiver_A_0": {"sender": 0, "receiver": 1, "receiver_params": {"receiver_type": "recurrent", "receiver_cell": "LSTM", "receiver_num_layers": 1, "receiver_hidden_size": 128, "receiver_embed_dim": 128}, "receiver_optim_params": {"optimizer": "adam", "loss": "cross_entropy", "p_step": 1, "lr": 0.0005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_decoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/receiver_default_reco_object_decoder.pt", "receiver": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_1/receiver_default_reco_receiver.pt"}}, "sender_B_0": {"sender": 1, "receiver": 0, "sender_params": {"sender_type": "recurrent", "sender_cell": "LSTM", "sender_num_layers": 1, "sender_hidden_size": 128, "sender_embed_dim": 128}, "sender_optim_params": {"optimizer": "adam", "loss": "REINFORCE", "reward": "log", "baseline": "normalization_batch", "p_step": 1, "lr": 0.0005, "entropy_reg_coef": 0.005}, "dataset": {"distribution": "uniform"}, "pretrained_modules": {"object_encoder": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/sender_default_reco_object_encoder.pt", "sender": "/Users/mrita/Desktop/Work/PhD/Population/default_experiment/default_models/expe_2/sender_default_reco_sender.pt"}}}