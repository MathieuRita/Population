{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e98165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeb749a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[ 0.0000e+00, -1.0000e+10, -1.0000e+10],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.0000e+10],\n",
      "        [-1.0000e+10, -1.0000e+10,  0.0000e+00]])\n",
      "cc\n",
      "tensor([1., 2., 1.])\n"
     ]
    }
   ],
   "source": [
    "inputs = th.Tensor([[1,0,0],[0,1,0],[0,0,1]])\n",
    "messages = th.Tensor([[0,0],[1,1],[2,2]])\n",
    "\n",
    "batch_size = messages.size(0)\n",
    "\n",
    "id_sampled_messages = np.arange(batch_size)\n",
    "sampled_messages = messages[id_sampled_messages]\n",
    "sampled_messages = sampled_messages.unsqueeze(0)\n",
    "sampled_messages = sampled_messages.repeat(batch_size, 1, 1)\n",
    "sampled_messages = sampled_messages.permute(1, 0, 2)\n",
    "sampled_messages = sampled_messages.reshape([batch_size * batch_size, sampled_messages.size(-1)])\n",
    "sampled_x = inputs.repeat(batch_size, 1, 1, 1)\n",
    "sampled_x = sampled_x.reshape([batch_size * batch_size, *inputs.size()[1:]])\n",
    "\n",
    "print(sampled_x)\n",
    "print(sampled_messages)\n",
    "\n",
    "eps=-10**10\n",
    "log_probs = th.Tensor([0,0,eps,eps,0,eps,eps,eps,0])\n",
    "#m1|x1, m2|x2, m3|x3, m2|x1, m2|x2, m2|x3, m3|x1, m3|x2, m3|x3\n",
    "\n",
    "log_pi_m_x = log_probs.reshape([batch_size, batch_size]).T\n",
    "pi_m_x = th.exp(log_pi_m_x)\n",
    "p_x = th.ones(batch_size) / batch_size  # Here we set p(x)=1/batch_size\n",
    "p_x = p_x.to(pi_m_x.device)  # Fix device issue\n",
    "\n",
    "print(log_pi_m_x)\n",
    "print(\"cc\")\n",
    "print(pi_m_x.sum(1))\n",
    "\n",
    "log_p_x = th.log(p_x)\n",
    "log_pi_m = th.log((pi_m_x * p_x).sum(1))\n",
    "log_pi_m_x = th.log(pi_m_x.diagonal(0))\n",
    "\n",
    "mutual_information = log_pi_m_x + log_p_x - log_pi_m\n",
    "\n",
    "loss_mi = -1*log_pi_m_x*mutual_information.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5196fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "target_messages=[]\n",
    "\n",
    "for sender_id in [\"_\",\"_\"]:\n",
    "    for _ in range(10):\n",
    "        messages = th.Tensor([[2,2],[1,1]])\n",
    "        target_messages.append(messages)\n",
    "\n",
    "target_messages=th.stack(target_messages)\n",
    "\n",
    "print(target_messages.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72645757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coucou\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "C = collections.namedtuple(\"Batch\",[\"data\",\"sender_id\",\"receiver_id\",\"imitator_id\"])\n",
    "\n",
    "a=C(sender_id=2,receiver_id=3,imitator_id=4,data=2)\n",
    "\n",
    "if getattr(a, \"sender_id\", False):\n",
    "    print(\"coucou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77aad176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mi_values=np.load(\"/Users/mrita/Desktop/Work/CUP/saved_mi_values.npy\")\n",
    "gene_labels=np.load(\"/Users/mrita/Desktop/Work/CUP/gene_labels.npy\")\n",
    "\n",
    "ordered_mi_idx = np.argsort(mi_values)[::-1]\n",
    "\n",
    "plt.plot(mi_values[ordered_mi_idx])\n",
    "plt.xlabel(\"Rank of genes\",size=13)\n",
    "plt.ylabel(\"Mutual information score\",size=13)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "print(np.sum(mi_values>0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b8e1f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "tensor([[6., 2., 3., 4., 5.],\n",
      "        [6., 2., 3., 1., 5.]])\n"
     ]
    }
   ],
   "source": [
    "voc_size=5\n",
    "\n",
    "messages=th.Tensor([[2,3,4,5],[2,3,1,5]])\n",
    "start_token = th.Tensor(messages.size(0)*[voc_size+1]).to(int)\n",
    "start_token = start_token.unsqueeze(1)\n",
    "messages = th.cat((start_token,messages),dim=1)\n",
    "\n",
    "print(messages.size())\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "39bfa137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b7eb2",
   "metadata": {},
   "source": [
    "# Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "1c82832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextGenerator(torch.nn.ModuleList):\n",
    "\n",
    "    def __init__(self, batch_size,hidden_dim, max_len, vocab_size,window):\n",
    "        super(TextGenerator, self).__init__()\n",
    "    \n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_size = vocab_size\n",
    "        self.num_classes = vocab_size\n",
    "        self.sequence_len = window\n",
    "    \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_dim, padding_idx=0)\n",
    "    \n",
    "        # Bi-LSTM\n",
    "        self.lstm_cell_forward = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n",
    "        self.lstm_cell_backward = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n",
    "        self.sender_norm_h_forward = nn.LayerNorm(self.hidden_dim)\n",
    "        self.sender_norm_h_backward = nn.LayerNorm(self.hidden_dim)\n",
    "        self.sender_norm_c_forward = nn.LayerNorm(self.hidden_dim)\n",
    "        self.sender_norm_c_backward = nn.LayerNorm(self.hidden_dim)\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm_cell = nn.GRUCell(self.hidden_dim, self.hidden_dim)\n",
    "        self.lstm_cell_2 = nn.GRUCell(self.hidden_dim, self.hidden_dim)\n",
    "        self.sender_norm_h = nn.LayerNorm(self.hidden_dim)\n",
    "        self.sender_norm_c = nn.LayerNorm(self.hidden_dim)\n",
    "    \n",
    "        # Linear layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.num_classes)\n",
    "        #self.linear = nn.Linear(self.sequence_len*self.hidden_dim, self.num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x,length):\n",
    "        \n",
    "\n",
    "        # LSTM\n",
    "        # hs = [batch_size x hidden_size]\n",
    "        # cs = [batch_size x hidden_size]\n",
    "        hs_forward = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cs_forward = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        hs_backward = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cs_backward = torch.zeros(x.size(0), self.hidden_dim)\n",
    "\n",
    "        # LSTM\n",
    "        # hs = [batch_size x (hidden_size * 2)]\n",
    "        # cs = [batch_size x (hidden_size * 2)]\n",
    "        hs_lstm = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cs_lstm = torch.zeros(x.size(0), self.hidden_dim)\n",
    "\n",
    "        # Weights initialization\n",
    "        #torch.nn.init.kaiming_normal_(hs_forward)\n",
    "        #torch.nn.init.kaiming_normal_(cs_forward)\n",
    "        #torch.nn.init.kaiming_normal_(hs_backward)\n",
    "        #torch.nn.init.kaiming_normal_(cs_backward)\n",
    "        #torch.nn.init.kaiming_normal_(hs_lstm)\n",
    "        #torch.nn.init.kaiming_normal_(cs_lstm)\n",
    "\n",
    "        # From idx to embedding\n",
    "        out = self.embedding(x)\n",
    "\n",
    "        # Prepare the shape for LSTM Cells\n",
    "        out = out.view(self.sequence_len, x.size(0), -1)\n",
    "\n",
    "        forward = []\n",
    "        backward = []\n",
    "        \n",
    "        \"\"\"\n",
    "        for i in range(self.sequence_len):\n",
    "            hs_forward, cs_forward = self.lstm_cell_forward(out[i], (hs_forward, cs_forward))\n",
    "            hs_forward = self.sender_norm_h_forward(hs_forward)\n",
    "            cs_forward = self.sender_norm_c_forward(cs_forward)\n",
    "            forward.append(hs_forward)\n",
    "\n",
    "        # Backward\n",
    "        for i in reversed(range(self.sequence_len)):\n",
    "            hs_backward, cs_backward = self.lstm_cell_backward(out[i], (hs_backward, cs_backward))\n",
    "            hs_backward = self.sender_norm_h_backward(hs_backward)\n",
    "            cs_backward = self.sender_norm_c_backward(cs_backward)\n",
    "            backward.append(hs_backward)\n",
    "\n",
    "        # LSTM\n",
    "        for fwd, bwd in zip(forward, backward):\n",
    "            input_tensor = torch.cat((fwd, bwd), 1)\n",
    "            hs_lstm, cs_lstm = self.lstm_cell(input_tensor, (hs_lstm, cs_lstm))\n",
    "            hs_lstm = self.sender_norm_h(hs_lstm)\n",
    "            cs_lstm = self.sender_norm_c(cs_lstm)\n",
    "        \"\"\"\n",
    "        hss=[]\n",
    "        css=[]\n",
    "        \n",
    "        for i in range(self.sequence_len):\n",
    "            hs_lstm = self.lstm_cell(out[i], hs_lstm)\n",
    "            \n",
    "            #hs_lstm, cs_lstm = self.lstm_cell(out[i], (hs_lstm, cs_lstm))\n",
    "            #hs_lstm=torch.nn.functional.normalize(hs_lstm)\n",
    "            #cs_lstm=torch.nn.functional.normalize(cs_lstm)\n",
    "            hs_lstm = self.sender_norm_h(hs_lstm)\n",
    "            #cs_lstm = self.sender_norm_c(cs_lstm)\n",
    "            hss.append(hs_lstm)\n",
    "            #css.append(cs_lstm)\n",
    "        \n",
    "        #hs_lstm_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        \n",
    "        #for i in range(self.sequence_len):\n",
    "        #    hs_lstm_2 = self.lstm_cell_2(hss[i], hs_lstm_2)\n",
    "            \n",
    "        \n",
    "            \n",
    "        length = nn.functional.one_hot(length-1,num_classes=self.sequence_len)\n",
    "        #length=1-torch.cumsum(length,dim=1)\n",
    "            \n",
    "        hs_out=torch.stack(hss,dim=1)\n",
    "        hs_out=length.unsqueeze(2).detach()*hs_out\n",
    "        hs_out=hs_out.sum(dim=1)\n",
    "        \n",
    "        hs_out = self.dropout(hs_out)\n",
    "        \n",
    "        #cs_out=torch.stack(css,dim=1)\n",
    "        #cs_out=length.unsqueeze(2)*cs_out\n",
    "        #cs_out=cs_out.sum(dim=1)\n",
    "        \n",
    "        #hss=torch.stack(hss,dim=1)\n",
    "        #hss=hss.resize(hss.size(0),hss.size(1)*hss.size(2))\n",
    "            \n",
    "        \n",
    "        #length = nn.functional.one_hot(length,num_classes=self.sequence_len)\n",
    "        #length=length.unsqueeze(2)\n",
    "        #length=length.repeat(1,1,self.hidden_dim)\n",
    "        #length=length.flatten(1)\n",
    "        # Last hidden state is passed through a linear layer\n",
    "        #hs_lstm=hs_lstm.repeat(1,self.sequence_len)\n",
    "    \n",
    "        #pre_out = hs_lstm * length\n",
    "        pre_out=hs_out\n",
    "        out = self.linear(pre_out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "9e5b7576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-torch.cumsum(torch.Tensor([[0,1,0,0],[0,0,1,0]]),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "836fdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,sequences,message_length,num_epochs,batch_size,hidden_dim,max_len,vocab_size,lr):\n",
    "    \n",
    "    \n",
    "    #params=list(model.embedding.parameters())\n",
    "    #params+=list(model.lstm_cell.parameters())\n",
    "    #params+=list(model.sender_norm_h.parameters())\n",
    "    #params+=list(model.sender_norm_c.parameters())\n",
    "    \n",
    "    # Optimizer initialization\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "    \n",
    "    ce = nn.CrossEntropyLoss(reduce=False)\n",
    "  \n",
    "    # Defining number of batches\n",
    "    num_batches = int(len(sequences) / batch_size)\n",
    "  \n",
    "    # Set model in training mode\n",
    "    model.train()\n",
    "  \n",
    "    # Training pahse\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "    \n",
    "        # Mini batches\n",
    "        for i in range(num_batches):\n",
    "      \n",
    "            # Batch definition\n",
    "            try:\n",
    "                x_batch = sequences[i * batch_size : (i + 1) * batch_size]\n",
    "                y_batch = targets[i * batch_size : (i + 1) * batch_size]\n",
    "                len_batch = message_length[i * batch_size : (i + 1) * batch_size]\n",
    "            except:\n",
    "                x_batch = sequences[i * batch_size :]\n",
    "                y_batch = targets[i * batch_size :]\n",
    "                len_batch = message_length[i * batch_size :]\n",
    "        \n",
    "        \n",
    "            # Convert numpy array into torch tensors\n",
    "            x = torch.from_numpy(x_batch).type(torch.LongTensor)\n",
    "            y = torch.from_numpy(y_batch).type(torch.LongTensor)\n",
    "            length = torch.from_numpy(len_batch).type(torch.LongTensor)\n",
    "            \n",
    "            # Feed the model\n",
    "            y_pred = model(x,length)\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss = ce(y_pred,y.squeeze())\n",
    "            \n",
    "            #print(loss)\n",
    "            \n",
    "            #print(y_pred,y.squeeze())\n",
    "            #print(loss)\n",
    "\n",
    "            # Clean gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate gradientes\n",
    "            loss.mean().backward()\n",
    "\n",
    "            # Updated parameters\n",
    "            optimizer.step()\n",
    "      \n",
    "        print(\"Epoch: %d ,  loss: %.5f \" % (epoch, loss.mean().item()))\n",
    "        \n",
    "        #if epoch%100==0:\n",
    "        #    scheduler.step()\n",
    "        \n",
    "        \n",
    "def generator(model, sequences, n_chars,window):\n",
    "  \n",
    "    # Set the model in evalulation mode\n",
    "    model.eval()\n",
    "  \n",
    "    # Define the softmax function\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "  \n",
    "    # Randomly is selected the index from the set of sequences\n",
    "    #start = np.random.randint(0, len(sequences)-1)\n",
    "    start=0\n",
    "  \n",
    "    # The pattern is defined given the random idx\n",
    "    pattern = sequences[start]\n",
    "  \n",
    "    # By making use of the dictionaries, it is printed the pattern\n",
    "    print(\"\\nPattern: \\n\")\n",
    "    print(''.join([str(value) for value in pattern]))\n",
    "  \n",
    "    # In full_prediction we will save the complete prediction\n",
    "    full_prediction = pattern.copy()\n",
    "  \n",
    "    # The prediction starts, it is going to be predicted a given\n",
    "    # number of characters\n",
    "    for i in range(n_chars):\n",
    "    \n",
    "        # The numpy patterns is transformed into a tesor-type and reshaped\n",
    "        new_pattern = torch.from_numpy(pattern).type(torch.LongTensor)\n",
    "        new_pattern=new_pattern[-window:]\n",
    "        new_pattern = new_pattern.view(1,-1)\n",
    "\n",
    "        # Make a prediction given the pattern\n",
    "        prediction = model(new_pattern)\n",
    "        # It is applied the softmax function to the predicted tensor\n",
    "        #prediction = softmax(prediction)\n",
    "        prediction=torch.exp(prediction)\n",
    "        print(prediction)\n",
    "\n",
    "        # The prediction tensor is transformed into a numpy array\n",
    "        prediction = prediction.squeeze().detach().numpy()\n",
    "        # It is taken the idx with the highest probability\n",
    "        arg_max = np.argmax(prediction)\n",
    "        \n",
    "        print(arg_max)\n",
    "        \n",
    "        # The current pattern tensor is transformed into numpy array\n",
    "        #pattern = pattern.squeeze().detach().numpy()\n",
    "        # The new pattern is composed by the \"old\" pattern + the predicted character\n",
    "        pattern = np.append(pattern, arg_max)\n",
    "\n",
    "    # The full prediction is saved\n",
    "    #full_prediction = np.append(full_prediction, arg_max)\n",
    "        \n",
    "    print(\"Prediction: \\n\")\n",
    "    print(''.join([str(value) for value in pattern]))\n",
    "    \n",
    "def get_prob(model, sequences, PAD=11, max_len=10):\n",
    "    \n",
    "    #sequences=np.array([[char] for char in sequences])\n",
    "  \n",
    "    # Set the model in evalulation mode\n",
    "    model.eval()\n",
    "  \n",
    "    # Define the softmax function\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "  \n",
    "    # Randomly is selected the index from the set of sequences\n",
    "    #start = np.random.randint(0, len(sequences)-1)\n",
    "    start=0\n",
    "  \n",
    "    # The pattern is defined given the random idx\n",
    "    pattern = [sequences[start]] + [PAD]*(max_len-1)\n",
    "  \n",
    "    # In full_prediction we will save the complete prediction\n",
    "    full_prediction = pattern.copy()\n",
    "    probs=[]\n",
    "\n",
    "    # The prediction starts, it is going to be predicted a given\n",
    "    # number of characters\n",
    "    for i in range(1,len(sequences)):\n",
    "        new_pattern=np.array([pattern])\n",
    "        # The numpy patterns is transformed into a tesor-type and reshaped\n",
    "        length = max_len-np.sum(new_pattern==11,axis=1)\n",
    "        print(length)\n",
    "        new_pattern = torch.from_numpy(new_pattern).type(torch.LongTensor)\n",
    "        length = torch.from_numpy(np.array(length)).type(torch.LongTensor)\n",
    "        new_pattern = new_pattern.view(1,-1)\n",
    "\n",
    "        # Make a prediction given the pattern\n",
    "        print(new_pattern)\n",
    "        prediction = model(new_pattern,length)\n",
    "        # It is applied the softmax function to the predicted tensor\n",
    "        prediction = softmax(prediction)\n",
    "\n",
    "        # The prediction tensor is transformed into a numpy array\n",
    "        prediction = prediction.squeeze().detach().numpy()\n",
    "        print(prediction,sequences[i])\n",
    "        # It is taken the idx with the highest probability\n",
    "        prob=prediction[sequences[i]]\n",
    "        arg_max = sequences[i]\n",
    "        \n",
    "        # The current pattern tensor is transformed into numpy array\n",
    "        #pattern = pattern.squeeze().detach().numpy()\n",
    "        # The new pattern is composed by the \"old\" pattern + the predicted character\n",
    "        pattern[i] = arg_max\n",
    "        probs.append(prob)\n",
    "\n",
    "    # The full prediction is saved\n",
    "    #full_prediction = np.append(full_prediction, arg_max)\n",
    "    print(np.prod(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd51989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(text, max_len):\n",
    "    x = list()\n",
    "    y = list()\n",
    "    PAD=11\n",
    "    \n",
    "    for seq in text:\n",
    "        for i in range(1,len(seq)):\n",
    "            s = seq[:i]+(max_len-i)*[PAD]\n",
    "            x.append(np.array(s))\n",
    "            y.append(np.array(seq[i]))\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "#print(build_sequences(text,window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "870787bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ,  loss: 0.44582 \n",
      "Epoch: 2 ,  loss: 0.43045 \n",
      "Epoch: 3 ,  loss: 0.43562 \n",
      "Epoch: 4 ,  loss: 0.45575 \n",
      "Epoch: 5 ,  loss: 0.49655 \n",
      "Epoch: 6 ,  loss: 0.46698 \n",
      "Epoch: 7 ,  loss: 0.45782 \n",
      "Epoch: 8 ,  loss: 0.46847 \n",
      "Epoch: 9 ,  loss: 0.46058 \n",
      "Epoch: 10 ,  loss: 0.45644 \n",
      "Epoch: 11 ,  loss: 0.45464 \n",
      "Epoch: 12 ,  loss: 0.43160 \n",
      "Epoch: 13 ,  loss: 0.43911 \n",
      "Epoch: 14 ,  loss: 0.44923 \n",
      "Epoch: 15 ,  loss: 0.45256 \n",
      "Epoch: 16 ,  loss: 0.46263 \n",
      "Epoch: 17 ,  loss: 0.45824 \n",
      "Epoch: 18 ,  loss: 0.46024 \n",
      "Epoch: 19 ,  loss: 0.44063 \n",
      "Epoch: 20 ,  loss: 0.45722 \n",
      "Epoch: 21 ,  loss: 0.45249 \n",
      "Epoch: 22 ,  loss: 0.48525 \n",
      "Epoch: 23 ,  loss: 0.46851 \n",
      "Epoch: 24 ,  loss: 0.49997 \n",
      "Epoch: 25 ,  loss: 0.46314 \n",
      "Epoch: 26 ,  loss: 0.44967 \n",
      "Epoch: 27 ,  loss: 0.46229 \n",
      "Epoch: 28 ,  loss: 0.45545 \n",
      "Epoch: 29 ,  loss: 0.47182 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-579-fd98747f24f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmessage_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmessage_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m#generator(model=model, sequences=np.array([[0]]), n_chars=9,window=window)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-573-1c4c90fe40b2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, sequences, message_length, num_epochs, batch_size, hidden_dim, max_len, vocab_size, lr)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Calculate gradientes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Updated parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_phd/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_phd/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text=[]\n",
    "\n",
    "for i in range(1,1000):\n",
    "    rd1=np.random.randint(2,4,1)[0]\n",
    "    #rd2=np.random.randint(2,5,1)[0]\n",
    "    rd2=rd1\n",
    "    text.append([0,rd1,rd2,1])\n",
    "\n",
    "\n",
    "lr=0.001\n",
    "num_epochs = 1000\n",
    "batch_size = 10\n",
    "hidden_dim = 128\n",
    "max_len = 4\n",
    "vocab_size = 12\n",
    "\n",
    "model = TextGenerator(batch_size=batch_size, \n",
    "                      hidden_dim=hidden_dim, \n",
    "                      max_len=max_len,\n",
    "                      window=max_len,\n",
    "                      vocab_size=vocab_size)\n",
    "\n",
    "sequences, targets = build_sequences(text,max_len=max_len)\n",
    "message_length = max_len-np.sum(sequences==11,axis=1)\n",
    "\n",
    "train(model,sequences,message_length,num_epochs,batch_size,hidden_dim,max_len,vocab_size,lr)\n",
    "#generator(model=model, sequences=np.array([[0]]), n_chars=9,window=window)\n",
    "\n",
    "\n",
    "#for i in range(1,12):\n",
    "#    test=[[0,i,1]]\n",
    "#    get_prob(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62992b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/6*(np.log(2)+np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "41146b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[1]\n",
      "tensor([[ 0, 11, 11, 11]])\n",
      "[3.8784510e-08 5.8387400e-07 4.7987333e-01 5.2012569e-01 4.0020321e-08\n",
      " 3.4352915e-08 3.7311793e-08 5.9340387e-08 3.0514514e-08 3.8158024e-08\n",
      " 3.6475978e-08 3.9666187e-08] 2\n",
      "[2]\n",
      "tensor([[ 0,  2, 11, 11]])\n",
      "[3.4308095e-11 3.1778409e-09 5.4009807e-01 4.5990190e-01 4.7046353e-11\n",
      " 4.3385712e-11 4.1363499e-11 6.1503434e-11 4.0545817e-11 4.4846241e-11\n",
      " 3.3379698e-11 4.3330142e-11] 2\n",
      "[3]\n",
      "tensor([[ 0,  2,  2, 11]])\n",
      "[1.07474765e-10 5.54179778e-08 5.44645905e-01 4.55354065e-01\n",
      " 1.32995143e-10 1.22945279e-10 1.16088743e-10 1.64411068e-10\n",
      " 1.16262909e-10 1.20910906e-10 8.95479524e-11 1.12130576e-10] 1\n",
      "1.4363158e-08\n",
      "3\n",
      "[1]\n",
      "tensor([[ 0, 11, 11, 11]])\n",
      "[3.8784510e-08 5.8387400e-07 4.7987333e-01 5.2012569e-01 4.0020321e-08\n",
      " 3.4352915e-08 3.7311793e-08 5.9340387e-08 3.0514514e-08 3.8158024e-08\n",
      " 3.6475978e-08 3.9666187e-08] 3\n",
      "[2]\n",
      "tensor([[ 0,  3, 11, 11]])\n",
      "[1.1417826e-08 8.5740581e-08 5.0513369e-01 4.9486622e-01 1.1350623e-08\n",
      " 9.8442268e-09 1.1332019e-08 1.2481494e-08 9.1909627e-09 1.2579892e-08\n",
      " 1.0551528e-08 1.3366957e-08] 3\n",
      "[3]\n",
      "tensor([[ 0,  3,  3, 11]])\n",
      "[6.3601995e-08 4.1479666e-06 4.1015750e-01 5.8983773e-01 5.7022795e-08\n",
      " 5.3824820e-08 7.9128299e-08 4.7228852e-08 6.2329605e-08 6.7284681e-08\n",
      " 6.0646634e-08 8.6094211e-08] 1\n",
      "1.0676561e-06\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,4):\n",
    "    j=i\n",
    "    print(i)\n",
    "    test=[0,i,j,1]\n",
    "    get_prob(model,test,max_len=4)\n",
    "        \n",
    "#print(\"Others\")\n",
    "#test=[0,1,2,1,1,1]\n",
    "#get_prob(model,test)\n",
    "#test=[0,2,1,1,1,1]\n",
    "#get_prob(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "8d1c9335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n",
      "[0, 3, 3, 1]\n",
      "[0, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,1000):\n",
    "    rd1=np.random.randint(2,4,1)[0]\n",
    "    #rd2=np.random.randint(2,5,1)[0]\n",
    "    rd2=rd1\n",
    "    print([0,rd1,rd2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a949d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,1000):\n",
    "    rd1=np.random.randint(0,5,1)[0]\n",
    "    print(rd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1900f7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10],\n",
      "        [10]])\n"
     ]
    }
   ],
   "source": [
    "message=th.zeros(20,10,10)\n",
    "voc_size=10\n",
    "\n",
    "start_token = th.Tensor(messages.size(0) * [voc_size]).to(int).to(messages.device)\n",
    "start_token = start_token.unsqueeze(1)\n",
    "\n",
    "print(start_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3220d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUP\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "cancer_types = {'Bladder': 0,\n",
    "                 'Brain': 1,\n",
    "                 'Breast': 2,\n",
    "                 'Cervix': 3,\n",
    "                 'Colon': 4,\n",
    "                 'CorpusUteri': 5,\n",
    "                 'HeadandNeck': 6,\n",
    "                 'Hematopoietic': 7,\n",
    "                 'Kidney': 8,\n",
    "                 'Liver': 9,\n",
    "                 'Lung': 10,\n",
    "                 'LymphNodes': 11,\n",
    "                 'Ovary': 12,\n",
    "                 'Pancreas': 13,\n",
    "                 'Prostate': 14,\n",
    "                 'Skyn': 15,\n",
    "                 'Stomach': 16,\n",
    "                 'ThyroidGland': 18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "3281a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_geness=[]\n",
    "accuracies=[]\n",
    "f1_scores=[]\n",
    "precisions=[]\n",
    "recalls=[]\n",
    "\n",
    "for nb_genes in range(10,2950,20):\n",
    "\n",
    "    cancer_labels = np.load(\"/Users/mrita/Desktop/Work/CUP/cancer_labels_val.npy\")\n",
    "    cancer_labels = [cancer_types[cancer] for cancer in cancer_labels]\n",
    "    preds = np.load(\"/Users/mrita/Desktop/Work/CUP/y_pred/nb_genes_{}.npy\".format(nb_genes))\n",
    "\n",
    "    accuracy = np.sum(cancer_labels==preds)/len(preds)\n",
    "    f1score=f1_score(cancer_labels,preds,average=None)\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(cancer_labels,preds)\n",
    "    \n",
    "    \n",
    "    nb_geness.append(nb_genes)\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(np.mean(f1score))\n",
    "    precisions.append(np.mean(precision))\n",
    "    recalls.append(np.mean(recall))\n",
    "    \n",
    "for nb_genes in range(3000,5000,50):\n",
    "\n",
    "    cancer_labels = np.load(\"/Users/mrita/Desktop/Work/CUP/cancer_labels_val.npy\")\n",
    "    cancer_labels = [cancer_types[cancer] for cancer in cancer_labels]\n",
    "    preds = np.load(\"/Users/mrita/Desktop/Work/CUP/y_pred/nb_genes_{}.npy\".format(nb_genes))\n",
    "\n",
    "    accuracy = np.sum(cancer_labels==preds)/len(preds)\n",
    "    f1score=f1_score(cancer_labels,preds,average=None)\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(cancer_labels,preds)\n",
    "    \n",
    "    nb_geness.append(nb_genes)\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(np.mean(f1score))\n",
    "    precisions.append(np.mean(precision))\n",
    "    recalls.append(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "2adf5af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nb_geness,accuracies)\n",
    "plt.plot([np.min(nb_geness),np.max(nb_geness)],[np.max(accuracies),np.max(accuracies)],\n",
    "         c=\"tab:red\",\n",
    "         linestyle=\"--\",\n",
    "        alpha=0.8,\n",
    "        label=\"top score\")\n",
    "plt.plot([nb_geness[np.argmax(accuracies)],nb_geness[np.argmax(accuracies)]],[0.85,np.max(accuracies)],\n",
    "         c=\"tab:green\",\n",
    "         linestyle=\"--\",\n",
    "        alpha=0.8,\n",
    "        label=\"Optimal number of genes\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of genes in features selection\",size=12)\n",
    "plt.ylabel(\"Test accuracy\",size=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(np.arange(0.85, 1, 0.02),fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(nb_geness,precisions)\n",
    "plt.plot([np.min(nb_geness),np.max(nb_geness)],[np.max(precisions),np.max(precisions)],\n",
    "         c=\"tab:red\",\n",
    "         linestyle=\"--\",\n",
    "        alpha=0.8,\n",
    "        label=\"top score\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of genes in features selection\",size=12)\n",
    "plt.ylabel(\"Test accuracy\",size=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(np.arange(0.85, 1, 0.02),fontsize=10)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(nb_geness,recalls)\n",
    "plt.plot([np.min(nb_geness),np.max(nb_geness)],[np.max(recalls),np.max(recalls)],\n",
    "         c=\"tab:red\",\n",
    "         linestyle=\"--\",\n",
    "        alpha=0.8,\n",
    "        label=\"top score\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of genes in features selection\",size=12)\n",
    "plt.ylabel(\"Test accuracy\",size=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(np.arange(0.85, 1, 0.02),fontsize=10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "10857363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BieberLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_layers, nb_lstm_units=100, embedding_dim=3, batch_size=2,vocab_size=5):\n",
    "        \n",
    "        super(BieberLSTM, self).__init__()\n",
    "        \n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_lstm_units = nb_lstm_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_vocab_words = vocab_size\n",
    "        self.padding_idx = 0\n",
    "        \n",
    "        self.word_embedding = nn.Embedding(\n",
    "            num_embeddings=self.nb_vocab_words,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            padding_idx=self.padding_idx\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.nb_lstm_units,\n",
    "            num_layers=self.nb_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        self.hidden_to_symbol = nn.Linear(self.nb_lstm_units, self.nb_vocab_words)\n",
    "\n",
    "        # build actual NN\n",
    "        #self.__build_model()\n",
    "\n",
    "    def __build_model(self):\n",
    "        # build embedding layer first\n",
    "        \n",
    "\n",
    "        # whenever the embedding sees the padding index it'll make the whole vector zeros\n",
    "        self.word_embedding = nn.Embedding(\n",
    "            num_embeddings=self.nb_vocab_words,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            padding_idx=self.padding_idx\n",
    "        )\n",
    "\n",
    "        # design LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.nb_lstm_units,\n",
    "            num_layers=self.nb_lstm_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # output layer which projects back to tag space\n",
    "        self.hidden_to_tag = nn.Linear(self.nb_lstm_units, self.nb_tags)\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_a = torch.randn(1,batch_size, self.nb_lstm_units)*0.\n",
    "        hidden_b = torch.randn(1,batch_size, self.nb_lstm_units)*0.\n",
    "        return (hidden_a, hidden_b)\n",
    "    \n",
    "    \n",
    "    def forward(self, X, X_lengths):\n",
    "        # reset the LSTM hidden state. Must be done before you run a new batch. Otherwise the LSTM will treat\n",
    "        # a new batch as a continuation of a sequence\n",
    "        \n",
    "        batch_size, seq_len = X.size()\n",
    "        \n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # ---------------------\n",
    "        # 1. embed the input\n",
    "        # Dim transformation: (batch_size, seq_len, 1) -> (batch_size, seq_len, embedding_dim)\n",
    "        X = self.word_embedding(X)\n",
    "    \n",
    "\n",
    "        # ---------------------\n",
    "        # 2. Run through RNN\n",
    "        # TRICK 2 ********************************\n",
    "        # Dim transformation: (batch_size, seq_len, embedding_dim) -> (batch_size, seq_len, nb_lstm_units)\n",
    "        \n",
    "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(X, X_lengths, batch_first=True)\n",
    "\n",
    "        # now run through LSTM\n",
    "        X, self.hidden = self.lstm(X, hidden)\n",
    "\n",
    "        # undo the packing operation\n",
    "        X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "        \n",
    "        print(X.size())\n",
    "\n",
    "        # ---------------------\n",
    "        # 3. Project to tag space\n",
    "        # Dim transformation: (batch_size, seq_len, nb_lstm_units) -> (batch_size * seq_len, nb_lstm_units)\n",
    "\n",
    "        # this one is a bit tricky as well. First we need to reshape the data so it goes into the linear layer\n",
    "        X = X.contiguous()\n",
    "        X = X.view(-1, X.shape[2])\n",
    "\n",
    "        # run through actual linear layer\n",
    "        X = self.hidden_to_symbol(X)\n",
    "\n",
    "        # ---------------------\n",
    "        # 4. Create softmax activations bc we're doing classification\n",
    "        # Dim transformation: (batch_size * seq_len, nb_lstm_units) -> (batch_size, seq_len, nb_tags)\n",
    "        X = F.log_softmax(X, dim=1)\n",
    "\n",
    "        # I like to reshape for mental sanity so we're back to (batch_size, seq_len, nb_tags)\n",
    "        X = X.view(batch_size, seq_len, self.nb_vocab_words)\n",
    "\n",
    "        Y_hat = X\n",
    "        return Y_hat\n",
    "    \n",
    "    \n",
    "    def loss(self, Y_hat, Y, X_lengths):\n",
    "        # TRICK 3 ********************************\n",
    "        # before we calculate the negative log likelihood, we need to mask out the activations\n",
    "        # this means we don't want to take into account padded items in the output vector\n",
    "        # simplest way to think about this is to flatten ALL sequences into a REALLY long sequence\n",
    "        # and calculate the loss on that.\n",
    "        \n",
    "        # create a mask by filtering out all tokens that ARE NOT the padding token\n",
    "        mask = nn.functional.one_hot(X_lengths,num_classes=Y_hat.size(1)+1)\n",
    "        mask= 1-torch.cumsum(mask,dim=1)[:,:-1]\n",
    "        # flatten all the labels\n",
    "        print(Y.size())\n",
    "        Y = Y.view(-1)\n",
    "        print(Y.size())\n",
    "\n",
    "        # flatten all predictions\n",
    "        Y_hat = Y_hat.view(-1, self.nb_vocab_words)\n",
    "        \n",
    "        \n",
    "        # count how many tokens we have\n",
    "        nb_tokens = int(torch.sum(mask).item())\n",
    "\n",
    "\n",
    "        # pick the values for the label and zero out the rest with the mask\n",
    "        Y_hat = Y_hat[range(Y_hat.size(0)), Y] * mask.view(-1)\n",
    "\n",
    "        # compute cross entropy loss which ignores all <PAD> tokens\n",
    "        ce_loss = -torch.sum(Y_hat) / nb_tokens\n",
    "\n",
    "        return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "ab98e3f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1048-7f5660ea3e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mask' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "b4d526b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 7, 2, 7, 2],\n",
       "         [1, 7, 7, 0, 0],\n",
       "         [1, 4, 5, 7, 2],\n",
       "         ...,\n",
       "         [1, 6, 3, 2, 2],\n",
       "         [1, 7, 2, 5, 2],\n",
       "         [1, 4, 7, 8, 2]]),\n",
       " tensor([[ 7,  2,  7,  2,  2],\n",
       "         [ 7,  7, 10,  0,  0],\n",
       "         [ 4,  5,  7,  2,  2],\n",
       "         ...,\n",
       "         [ 6,  3,  2,  2,  2],\n",
       "         [ 7,  2,  5,  2,  2],\n",
       "         [ 4,  7,  8,  2,  2]]),\n",
       " tensor([5, 3, 5,  ..., 5, 5, 5]))"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_dataset(sequences,padding_idx=0,max_len=4):\n",
    "    \n",
    "    X=[]\n",
    "    y=[]\n",
    "    X_length=[]\n",
    "    \n",
    "    for seq in sequences:\n",
    "        X.append(seq[:-1]+[padding_idx]*(max_len-1-len(seq[:-1])))\n",
    "        y.append(seq[1:]+[padding_idx]*(max_len-1-len(seq[1:])))\n",
    "        X_length.append(len(seq)-1)\n",
    "        \n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    X_length=np.array(X_length)\n",
    "        \n",
    "    X=torch.Tensor(X).to(int)\n",
    "    y=torch.Tensor(y).to(int)\n",
    "    X_length=torch.Tensor(X_length).to(int)\n",
    "    \n",
    "    return X,y,X_length\n",
    "\n",
    "build_dataset(sequences,max_len=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "9498b1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1]])\n",
      "tensor([[ 1.,  7., 10.,  3.,  4.,  4.],\n",
      "        [ 1.,  4.,  4., 11.,  4.,  4.],\n",
      "        [ 1., 10.,  6.,  8.,  4.,  4.],\n",
      "        ...,\n",
      "        [ 1.,  6.,  9.,  5.,  4.,  4.],\n",
      "        [ 1., 10.,  3.,  8.,  4.,  4.],\n",
      "        [ 1., 11.,  7.,  6.,  4.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "PAD_TOKEN = 0\n",
    "START_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "\n",
    "sequences=[]\n",
    "\n",
    "for i in range(5000):\n",
    "    rd1=np.random.randint(1,10,1)[0]\n",
    "    rd2=np.random.randint(1,10,1)[0]\n",
    "    rd3=np.random.randint(1,10,1)[0]\n",
    "    sequences.append([rd1,rd2,rd3,2,2])\n",
    "\n",
    "for j in range(1000):\n",
    "    sequences.append([7,7,0,0,0])\n",
    "    \n",
    "np.random.shuffle(sequences)\n",
    "\n",
    "max_len=np.max([len(seq) for seq in sequences])\n",
    "batch_size=128\n",
    "vocab_size=10\n",
    "\n",
    "X,y,X_lengths = build_data_lm(th.Tensor(sequences))\n",
    "\n",
    "model = BieberLSTM(nb_layers=1,\n",
    "                   nb_lstm_units=100, \n",
    "                   embedding_dim=10, \n",
    "                   batch_size=batch_size,\n",
    "                   vocab_size=vocab_size+2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "d631ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "Epoch 1 : loss=1.276843547821045\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "Epoch 2 : loss=1.247272253036499\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "Epoch 3 : loss=1.2382601499557495\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "Epoch 4 : loss=1.233784794807434\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "Epoch 5 : loss=1.2308827638626099\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "Epoch 6 : loss=1.228861689567566\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "Epoch 7 : loss=1.2275103330612183\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 5, 100])\n",
      "torch.Size([128, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1079-99e4a45a393e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mY_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1077-fcb59528ec4d>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, Y_hat, Y, X_lengths)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# flatten all the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=0.001\n",
    "num_epochs=400\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "model.train()\n",
    "\n",
    "num_batches = int(X.size(0) / batch_size)\n",
    "  \n",
    "# Training pahse\n",
    "for epoch in range(1,num_epochs+1):\n",
    "\n",
    "    # Mini batches\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        x_batch = X[i * batch_size : (i + 1) * batch_size]\n",
    "        y_batch = y[i * batch_size : (i + 1) * batch_size]\n",
    "        len_batch = X_lengths[i * batch_size : (i + 1) * batch_size]\n",
    "        \n",
    "        idx_sorted=torch.argsort(len_batch,descending=True)  \n",
    "        x_batch=x_batch[idx_sorted]\n",
    "        y_batch=y_batch[idx_sorted]\n",
    "        len_batch=len_batch[idx_sorted]\n",
    "    \n",
    "        Y_hat = model(x_batch,len_batch)\n",
    "        loss = model.loss(Y_hat=Y_hat, Y=y_batch, X_lengths=len_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Updated parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Epoch {} : loss={}\".format(epoch,loss.detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "e7ea79f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  4, 11,  7,  4])\n",
      "tensor(0.0008, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def get_prob(model,X_test,X_lengths_test,y_test,nb_vocab_words,batch_size,seq_len):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    Y_hat = model(X_test,X_lengths_test)\n",
    "    mask = nn.functional.one_hot(X_lengths_test,num_classes=seq_len+1)\n",
    "    mask= 1-torch.cumsum(mask,dim=1)[:,:-1]\n",
    "    \n",
    "    Y_hat = Y_hat*mask.unsqueeze(2)\n",
    "    Y_hat = torch.exp(Y_hat)\n",
    "    Y_hat = Y_hat.view(-1, nb_vocab_words)\n",
    "\n",
    "    Y = y_test.view(-1)\n",
    "    Y_hat=Y_hat[range(Y_hat.size(0)),Y]\n",
    "    Y_hat=Y_hat.resize(batch_size,seq_len)\n",
    "\n",
    "    return Y_hat.prod(1)\n",
    "\n",
    "sequences_test=[]\n",
    "\n",
    "sequences_test.append([7,7,0,0,0])\n",
    "\n",
    "for i in range(5000):\n",
    "    rd1=np.random.randint(1,10,1)[0]\n",
    "    rd2=np.random.randint(1,10,1)[0]\n",
    "    rd3=np.random.randint(1,10,1)[0]\n",
    "    sequences_test.append([rd1,rd2,rd3,2,2])\n",
    "\n",
    "    \n",
    "max_len_test=np.max([len(seq) for seq in sequences_test])\n",
    "\n",
    "X_test,y_test,X_lengths_test = build_data_lm(th.Tensor(sequences_test))\n",
    "\n",
    "idx_sorted=torch.argsort(X_lengths_test,descending=True)  \n",
    "idx_sorted_inv = torch.empty_like(idx_sorted)\n",
    "idx_sorted_inv[idx_sorted] = torch.arange(idx_sorted.size(0), device=idx_sorted.device)\n",
    "X_test=X_test[idx_sorted]\n",
    "y_test=y_test[idx_sorted]\n",
    "X_lengths_test=X_lengths_test[idx_sorted]\n",
    "\n",
    "vocab_size=12\n",
    "\n",
    "probs=get_prob(model,X_test,X_lengths_test,y_test,nb_vocab_words=vocab_size,batch_size=X_test.size(0),seq_len=X_test.size(1))\n",
    "\n",
    "X_test=X_test[idx_sorted_inv]\n",
    "y_test=y_test[idx_sorted_inv]\n",
    "X_lengths_test=X_lengths_test[idx_sorted_inv]\n",
    "probs=probs[idx_sorted_inv]\n",
    "\n",
    "print(X_test[2])\n",
    "print(probs[2].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "6acbe9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  3.,  4.,  5.,  2.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 1., 10., 10., 10., 10., 10.,  2.,  0.,  0.,  0.],\n",
       "         [ 1.,  3.,  4.,  5.,  6.,  6.,  5.,  2.,  0.,  0.]]),\n",
       " tensor([[ 3.,  4.,  5.,  2.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [10., 10., 10., 10., 10.,  2.,  0.,  0.,  0.,  0.],\n",
       "         [ 3.,  4.,  5.,  6.,  6.,  5.,  2.,  0.,  0.,  0.]]),\n",
       " [])"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_TOKEN=0\n",
    "START_TOKEN=1\n",
    "EOS_TOKEN=2\n",
    "\n",
    "def build_data_lm(messages, max_len):\n",
    "    x = []\n",
    "    y = []\n",
    "    x_length = []\n",
    "\n",
    "    messages = EOS_TOKEN + torch.Tensor(messages)\n",
    "    messages=torch.cat((torch.Tensor([START_TOKEN]*messages.size(0)).unsqueeze(1),messages),dim=1)\n",
    "\n",
    "    eos_mask = messages == EOS_TOKEN\n",
    "    x_lengths = max_len+1 - (eos_mask.cumsum(dim=1) > 0).sum(dim=1)\n",
    "    x_lengths.add_(1).clamp_(max=max_len+1)\n",
    "\n",
    "    pad_mask=1-torch.cumsum(1*eos_mask,dim=1)\n",
    "    messages = messages * pad_mask\n",
    "    messages += EOS_TOKEN* eos_mask\n",
    "    \n",
    "    x=messages[:,:-1]\n",
    "    y=messages[:,1:]\n",
    "    x_lengths=message_lengths-1\n",
    "    \n",
    "\n",
    "    return x, y, x_length\n",
    "\n",
    "\n",
    "max_len=10\n",
    "\n",
    "messages=torch.Tensor([[1,2,3,0,4,3,5,2,9,9],\n",
    "                      [8,8,8,8,8,0,8,8,8,8],\n",
    "                      [1,2,3,4,4,3,0,2,9,9]])\n",
    "\n",
    "build_data_lm(messages,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "1d6b291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  3.,  4.,  5.,  2.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1., 10., 10., 10., 10., 10.,  2.,  0.,  0.,  0.],\n",
      "        [ 1.,  3.,  4.,  5.,  6.,  6.,  5.,  2.,  0.,  0.]])\n",
      "tensor([[ 3.,  4.,  5.,  2.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [10., 10., 10., 10., 10.,  2.,  0.,  0.,  0.,  0.],\n",
      "        [ 3.,  4.,  5.,  6.,  6.,  5.,  2.,  0.,  0.,  0.]])\n",
      "tensor([4, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "EOS_TOKEN=2\n",
    "max_len=10\n",
    "\n",
    "messages=torch.Tensor([[1,2,3,0,4,3,5,2,9,9],\n",
    "                      [8,8,8,8,8,0,8,8,8,8],\n",
    "                      [1,2,3,4,4,3,0,2,9,9]])\n",
    "\n",
    "messages = EOS_TOKEN+messages\n",
    "messages=torch.cat((torch.Tensor([START_TOKEN]*messages.size(0)).unsqueeze(1),messages),dim=1)\n",
    "\n",
    "eos_mask = messages == EOS_TOKEN\n",
    "message_lengths = max_len+1 - (eos_mask.cumsum(dim=1) > 0).sum(dim=1)\n",
    "message_lengths.add_(1).clamp_(max=max_len+1)\n",
    "\n",
    "pad_mask=1-torch.cumsum(1*eos_mask,dim=1)\n",
    "messages = messages * pad_mask\n",
    "messages += 2* eos_mask\n",
    "\n",
    "x=messages[:,:-1]\n",
    "y=messages[:,1:]\n",
    "x_lengths=message_lengths-1\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(x_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "4776d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 1.,  3.,  4.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1., 10., 10., 10., 10., 10.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  3.,  4.,  5.,  6.,  6.,  5.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  3.,  4.,  5.,  6.,  6.,  5., 10.,  4., 11., 11.],\n",
      "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  3,  4,  5,  2,  0,  0,  0,  0,  0],\n",
       "         [ 1, 10, 10, 10, 10, 10,  2,  0,  0,  0],\n",
       "         [ 1,  3,  4,  5,  6,  6,  5,  2,  0,  0],\n",
       "         [ 1,  3,  4,  5,  6,  6,  5, 10,  4, 11],\n",
       "         [ 1,  2,  2,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " tensor([[ 3,  4,  5,  2,  0,  0,  0,  0,  0,  0],\n",
       "         [10, 10, 10, 10, 10,  2,  0,  0,  0,  0],\n",
       "         [ 3,  4,  5,  6,  6,  5,  2,  0,  0,  0],\n",
       "         [ 3,  4,  5,  6,  6,  5, 10,  4, 11, 11],\n",
       "         [ 2,  2,  0,  0,  0,  0,  0,  0,  0,  2]]),\n",
       " tensor([ 5,  7,  8, 10,  2]))"
      ]
     },
     "execution_count": 1073,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_TOKEN = 0\n",
    "START_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "\n",
    "import torch as th\n",
    "messages=torch.Tensor([[1,2,3,0,4,3,5,2,9,9],\n",
    "                      [8,8,8,8,8,0,8,8,8,8],\n",
    "                      [1,2,3,4,4,3,0,2,9,9],\n",
    "                      [1,2,3,4,4,3,8,2,9,9],\n",
    "                      [0, 0, 8, 8, 8, 5, 5, 7, 6, 0]]).to(float)\n",
    "\n",
    "def build_data_lm(messages):\n",
    "\n",
    "    max_len = messages.size(1)\n",
    "\n",
    "    messages = EOS_TOKEN + messages\n",
    "    start_tokens = th.Tensor([START_TOKEN] * messages.size(0)).unsqueeze(1).to(messages.device)\n",
    "    messages = th.cat((start_tokens, messages), dim=1)\n",
    "\n",
    "    eos_mask = messages == EOS_TOKEN\n",
    "    message_lengths = max_len + 1 - (eos_mask.cumsum(dim=1) > 0).sum(dim=1)\n",
    "    message_lengths.add_(1).clamp_(max=max_len)\n",
    "    \n",
    "    pad_mask = 1 - th.cumsum(1 * eos_mask, dim=1).clamp_(max=1)\n",
    "    messages = messages * pad_mask\n",
    "    messages += EOS_TOKEN * eos_mask\n",
    "    \n",
    "    messages.to(int)\n",
    "\n",
    "    x = messages[:, :-1].to(int)\n",
    "    y = messages[:, 1:].to(int)\n",
    "    x_lengths = (message_lengths).to(int)\n",
    "\n",
    "    return x, y, x_lengths\n",
    "\n",
    "build_data_lm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "9d59f8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 0, 0, 0, 0, 0, 0],\n",
       "         [8, 8, 8, 8, 8, 0, 0, 0, 0],\n",
       "         [1, 2, 3, 4, 4, 3, 0, 0, 0],\n",
       "         [1, 2, 3, 4, 4, 3, 8, 2, 9]]),\n",
       " tensor([[2, 3, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [8, 8, 8, 8, 0, 0, 0, 0, 0],\n",
       "         [2, 3, 4, 4, 3, 0, 0, 0, 0],\n",
       "         [2, 3, 4, 4, 3, 8, 2, 9, 9]]),\n",
       " tensor([3, 5, 6, 9]))"
      ]
     },
     "execution_count": 1062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_dataset(sequences,padding_idx=0,max_len=4):\n",
    "    \n",
    "    X=[]\n",
    "    y=[]\n",
    "    X_length=[]\n",
    "    \n",
    "    for seq in sequences:\n",
    "        X.append(seq[:-1]+[padding_idx]*(max_len-1-len(seq[:-1])))\n",
    "        y.append(seq[1:]+[padding_idx]*(max_len-1-len(seq[1:])))\n",
    "        X_length.append(len(seq)-1)\n",
    "        \n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    X_length=np.array(X_length)\n",
    "        \n",
    "    X=torch.Tensor(X).to(int)\n",
    "    y=torch.Tensor(y).to(int)\n",
    "    X_length=torch.Tensor(X_length).to(int)\n",
    "    \n",
    "    return X,y,X_length\n",
    "\n",
    "messages=[[1,2,3,0],\n",
    "          [8,8,8,8,8,0],\n",
    "          [1,2,3,4,4,3,0],\n",
    "          [1,2,3,4,4,3,8,2,9,9]]\n",
    "\n",
    "build_dataset(messages,max_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "id": "c3877cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = {'rnn': nn.RNNCell, 'gru': nn.GRUCell, 'LSTM': nn.LSTM}\n",
    "PAD_TOKEN = 0\n",
    "START_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "\n",
    "\n",
    "def build_data_lm(messages):\n",
    "\n",
    "    max_len = messages.size(1)\n",
    "\n",
    "    messages = EOS_TOKEN + messages\n",
    "    start_tokens = th.Tensor([START_TOKEN] * messages.size(0)).unsqueeze(1).to(messages.device)\n",
    "    messages = th.cat((start_tokens, messages), dim=1)\n",
    "\n",
    "    eos_mask = messages == EOS_TOKEN\n",
    "    message_lengths = max_len + 1 - (eos_mask.cumsum(dim=1) > 0).sum(dim=1)\n",
    "    message_lengths.add_(1).clamp_(max=max_len)\n",
    "\n",
    "    pad_mask = 1 - th.cumsum(1 * eos_mask, dim=1).clamp_(max=1)\n",
    "    messages = messages * pad_mask\n",
    "    messages += EOS_TOKEN * eos_mask\n",
    "    messages = messages.to(int)\n",
    "\n",
    "    x = messages[:, :-1]\n",
    "    y = messages[:, 1:]\n",
    "    x_lengths = message_lengths - 1\n",
    "\n",
    "    return x, y, x_lengths\n",
    "\n",
    "\n",
    "class LanguageModel():\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 optimizer,\n",
    "                 batch_size):\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def get_prob_messages(self, messages):\n",
    "\n",
    "        # Gerer le pb descending order pour les lengths\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        with th.no_grad():\n",
    "            x_test, y_test, x_lengths_test = build_data_lm(messages=messages)\n",
    "            \n",
    "            print(x_test[-10:],x_lengths_test[-10:])\n",
    "            print(y_test[-10:])\n",
    "\n",
    "            # Reorder by length\n",
    "            y_hat = self.model(x_test, x_lengths_test)\n",
    "            \n",
    "            print(y_hat[-10:])\n",
    "\n",
    "            batch_size, seq_len, nb_vocab_words = y_hat.size()\n",
    "            mask = nn.functional.one_hot(x_lengths_test, num_classes=seq_len + 1)\n",
    "            mask = 1 - th.cumsum(mask, dim=1)[:, :-1]\n",
    "\n",
    "            y_hat = y_hat * mask.unsqueeze(2)\n",
    "            y_hat = th.exp(y_hat)\n",
    "            y_hat = y_hat.contiguous()\n",
    "            y_hat = y_hat.view(-1, self.model.voc_size)\n",
    "\n",
    "            y_test = y_test.contiguous()\n",
    "            y_hat = y_hat[range(y_hat.size(0)), y_test.view(-1)]\n",
    "            y_hat = y_hat.resize(batch_size, seq_len)\n",
    "            \n",
    "            print(y_hat[-10:])\n",
    "\n",
    "        return y_hat.prod(1)\n",
    "\n",
    "    def compute_loss(self, y_hat, y, x_lengths):\n",
    "\n",
    "        # create a mask by filtering out all tokens that ARE NOT the padding token\n",
    "        mask = F.one_hot(x_lengths, num_classes=y_hat.size(1) + 1)\n",
    "        mask = 1 - th.cumsum(mask, dim=1)[:, :-1]\n",
    "        mask = mask.to(y_hat.device)\n",
    "\n",
    "        # flatten all the labels\n",
    "        y = y.contiguous()\n",
    "        y = y.view(-1)\n",
    "\n",
    "        # flatten all predictions\n",
    "        y_hat = y_hat.contiguous()\n",
    "        y_hat = y_hat.view(-1, self.model.voc_size)\n",
    "\n",
    "        # count how many tokens we have\n",
    "        nb_tokens = int(th.sum(mask).item())\n",
    "\n",
    "        # pick the values for the label and zero out the rest with the mask\n",
    "        y_hat = y_hat[range(y_hat.size(0)), y] * mask.view(-1)\n",
    "\n",
    "        # compute cross entropy loss which ignores all <PAD> tokens\n",
    "        ce_loss = -th.sum(y_hat) / nb_tokens\n",
    "\n",
    "        return ce_loss\n",
    "\n",
    "    def train(self,\n",
    "              messages,\n",
    "              n_epochs: int = 200,\n",
    "              threshold: float = 1e-2):\n",
    "\n",
    "        x, y, x_lengths = build_data_lm(messages=messages)\n",
    "        \n",
    "        r=torch.randperm(x.size(0))\n",
    "        x=x[r]\n",
    "        y=y[r]\n",
    "        x_lengths=x_lengths[r]\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        num_batches = int(x.size(0) / self.batch_size)\n",
    "\n",
    "        prev_losses = []\n",
    "\n",
    "        continue_training = True\n",
    "        epoch = 0\n",
    "\n",
    "        while continue_training:\n",
    "\n",
    "            mean_loss=0.\n",
    "\n",
    "            # Mini batches\n",
    "            for i in range(num_batches):\n",
    "                x_batch = x[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "                y_batch = y[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "                len_batch = x_lengths[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "\n",
    "                y_hat = self.model(x_batch, len_batch)\n",
    "                loss = self.compute_loss(y_hat, y_batch, len_batch)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Calculate gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Updated parameters\n",
    "                self.optimizer.step()\n",
    "\n",
    "                mean_loss+=loss.item()\n",
    "\n",
    "            mean_loss/=num_batches\n",
    "            \n",
    "            print(mean_loss,abs(mean_loss - np.mean(prev_losses)))\n",
    "\n",
    "            if (len(prev_losses) > 4 and abs(mean_loss - np.mean(prev_losses)) < threshold) or epoch >= n_epochs:\n",
    "                continue_training = False\n",
    "            else:\n",
    "                prev_losses.append(mean_loss)\n",
    "                epoch += 1\n",
    "                if len(prev_losses) > 5 : prev_losses.pop(0)\n",
    "\n",
    "\n",
    "class LanguageModelNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_len: int,\n",
    "                 voc_size: int,\n",
    "                 num_layers: int = 1,\n",
    "                 hidden_size: int = 128,\n",
    "                 embedding_size: int = 20,\n",
    "                 device : str =\"cpu\") -> None:\n",
    "        super(LanguageModelNetwork, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.voc_size = voc_size\n",
    "        self.max_len = max_len\n",
    "        self.device=device\n",
    "\n",
    "        self.word_embedding = nn.Embedding(\n",
    "            num_embeddings=self.voc_size,\n",
    "            embedding_dim=self.embedding_size,\n",
    "            padding_idx=PAD_TOKEN\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.hidden_to_symbol = nn.Linear(self.hidden_size, self.voc_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden_a = th.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n",
    "        hidden_b = th.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n",
    "        return hidden_a, hidden_b\n",
    "\n",
    "    def forward(self, x, x_lengths):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Prepare data\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        x = self.word_embedding(x)\n",
    "\n",
    "        x = th.nn.utils.rnn.pack_padded_sequence(x, x_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # now run through LSTM\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "\n",
    "        # undo the packing operation\n",
    "        x, _ = th.nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "        if x.size(1) < self.max_len:\n",
    "            dummy_tensor = th.zeros((batch_size,self.max_len - x.size(1), x.size(2)),device=self.device)\n",
    "            x = th.cat([x, dummy_tensor], 1)\n",
    "\n",
    "        x = x.contiguous()\n",
    "        x = x.view(-1, x.size(2))\n",
    "\n",
    "        # Pass through actual linear layer\n",
    "        y_hat = self.hidden_to_symbol(x)\n",
    "        y_hat = F.log_softmax(y_hat, dim=1)\n",
    "        y_hat = y_hat.view(batch_size, self.max_len, self.voc_size)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "def get_language_model(lm_params:dict,game_params:dict,device:str):\n",
    "\n",
    "    model = LanguageModelNetwork(max_len=game_params[\"channel\"][\"max_len\"],\n",
    "                                 voc_size=game_params[\"channel\"][\"voc_size\"]+2,\n",
    "                                 num_layers=lm_params[\"num_layers\"],\n",
    "                                 hidden_size=lm_params[\"hidden_size\"],\n",
    "                                 embedding_size=lm_params[\"embedding_size\"],\n",
    "                                 device=device)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = th.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "    language_model = LanguageModel(model=model,optimizer=optimizer,batch_size=lm_params[\"batch_size\"])\n",
    "\n",
    "    return language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "id": "b92dce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1557879447937012 nan\n",
      "1.0798795845197595 0.07590836027394166\n",
      "1.077527087667714 0.040306676989016355\n",
      "1.0766051541204038 0.02779305153998779\n",
      "1.0761058641516643 0.021344078623730445\n",
      "1.0757886896962705 0.01739243735437812\n",
      "1.0755648276080256 0.001616448423136907\n",
      "1.0753940006960994 0.0009243239527161329\n",
      "1.0752565212871716 0.0006351859673210392\n",
      "1.0751422825066939 0.00047969818115234375\n",
      "1.0750439581663713 0.0003853061924810053\n",
      "1.074955429719842 0.0003248883330302377\n",
      "1.0748750567436218 0.0002833817316136855\n",
      "1.074804046879644 0.00025060280509592303\n",
      "1.0747401273768882 0.00022402742634652917\n",
      "1.0746815878411997 0.0002021359360735442\n",
      "1.0746273657549983 0.00018388395724100448\n",
      "1.0745774870333464 0.00016814988592406266\n",
      "1.0745317884113477 0.00015433456586766425\n",
      "1.074488657972087 0.00014301331146926444\n",
      "1.0744468025539233 0.0001345748486727416\n",
      "1.0744041670923647 0.0001302532527758249\n",
      "1.074359030827232 0.0001307497853817452\n",
      "1.0743153069330298 0.0001307824383609546\n",
      "1.07427128760711 0.00013150546861728785\n",
      "1.0742250810498777 0.00013423795285416595\n",
      "1.0741768557092417 0.00013811899268101335\n",
      "1.0741264120392178 0.00014310038608056352\n",
      "1.0740738977556643 0.00014909091203119118\n",
      "1.0740199244540671 0.0001547823781551383\n",
      "1.0739651711090752 0.000159263092538664\n",
      "1.0739102778227434 0.00016217439070964623\n",
      "1.0738559339357459 0.0001632027004074832\n",
      "1.0738026603408481 0.00016238067461116223\n",
      "1.0737507861593496 0.00016000737314625368\n",
      "1.0737004953881968 0.0001564704853556087\n",
      "1.0736514511315718 0.00015257959780501373\n",
      "1.0736032672550366 0.0001489981361058046\n",
      "1.0735564516938252 0.0001452803611754483\n",
      "1.0735116082689036 0.0001408820566926039\n",
      "1.073469060918559 0.0001355938289477887\n",
      "1.0734287111655525 0.00012965668802689123\n",
      "1.073390286901723 0.00012353295865241698\n",
      "1.0733534304992012 0.0001177932905114254\n",
      "1.0733178232027136 0.00011279634807448424\n",
      "1.0732832291851873 0.00010863335236233063\n",
      "1.0732493685639424 0.00010532762693316045\n",
      "1.0732160651165505 0.00010276255400287759\n",
      "1.0731833136599997 0.00010066965351929191\n",
      "1.0731510960537454 9.886389193325407e-05\n"
     ]
    }
   ],
   "source": [
    "LM=get_language_model({\"batch_size\":128,\"num_layers\":1,\"hidden_size\":128,\"embedding_size\":40},{\"channel\":{\"max_len\":5,\"voc_size\":5}},device=\"cpu\")\n",
    "\n",
    "sequences=[]\n",
    "\n",
    "for i in range(5000):\n",
    "    rd1=np.random.randint(1,4,1)[0]\n",
    "    rd2=np.random.randint(1,4,1)[0]\n",
    "    rd3=np.random.randint(1,4,1)[0]\n",
    "    rd4=np.random.randint(1,4,1)[0]\n",
    "    sequences.append([rd1,rd2,rd3,rd4,2])\n",
    "\n",
    "for j in range(1000):\n",
    "    sequences.append([4,4,0,0,0])\n",
    "    \n",
    "messages=th.Tensor(sequences)\n",
    "\n",
    "LM.train(messages,threshold=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "id": "0a3643d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2],\n",
      "        [1, 6, 6, 2, 2]]) tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([[6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2],\n",
      "        [6, 6, 2, 2, 2]])\n",
      "tensor([[[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]],\n",
      "\n",
      "        [[-1.6887e+01, -1.6989e+01, -1.7292e+01, -1.2289e+00, -1.3083e+00,\n",
      "          -1.2757e+00, -1.8460e+00],\n",
      "         [-1.9589e+01, -2.0113e+01, -1.6168e+01, -1.4851e+01, -1.4629e+01,\n",
      "          -1.5075e+01, -1.1921e-06],\n",
      "         [-1.7242e+01, -1.7313e+01, -1.1921e-07, -2.3737e+01, -2.3813e+01,\n",
      "          -2.3906e+01, -1.6952e+01],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00],\n",
      "         [-2.0021e+00, -1.9691e+00, -2.0072e+00, -1.8853e+00, -1.9187e+00,\n",
      "          -1.9788e+00, -1.8696e+00]]])\n",
      "tensor([[0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1579, 1.0000, 1.0000, 1.0000, 1.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1579)"
      ]
     },
     "execution_count": 1118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM.get_prob_messages(messages)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "id": "03e5b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n",
      "tensor([0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "['Listener_1', 'Listener2']\n"
     ]
    }
   ],
   "source": [
    "agent_names = [\"Speaker_1\",\"Listener_1\",\"Listener_2\"]\n",
    "\n",
    "population_probs = th.zeros((3,3))\n",
    "population_probs[0,1]=1\n",
    "population_probs[0,2]=1\n",
    "\n",
    "population_probs /= population_probs.sum()\n",
    "\n",
    "population_probs = population_probs.flatten()\n",
    "\n",
    "print(population_probs.size())\n",
    "\n",
    "print(population_probs)\n",
    "\n",
    "sampled_pair_id = th.multinomial(population_probs, 1)\n",
    "\n",
    "grid_names=[(agent_names[i], agent_names[j]) for i in range(len(agent_names)) for j in range(len(agent_names))]\n",
    "\n",
    "sender_id=grid_names[sampled_pair_id][0]\n",
    "\n",
    "receiver_ids=[name[1] for j,name in enumerate(grid_names) if name[0]==sender_id and population_probs[j]>0]\n",
    "\n",
    "print(receiver_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f0badb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "batch_size=1024\n",
    "n_pairs=100\n",
    "n_attributes=5\n",
    "max_len=10\n",
    "\n",
    "inputs = np.random.randint(0,50,size=(batch_size,n_attributes))\n",
    "messages = np.random.randint(0,10,size=(batch_size,max_len))\n",
    "messages_len = 10*np.ones((batch_size),dtype=int)\n",
    "\n",
    "idx=np.random.randint(0,batch_size,n_pairs*2)\n",
    "\n",
    "inputs_pairs = inputs[idx].reshape((n_pairs,2,-1))\n",
    "messages_pairs = inputs[idx].reshape((n_pairs,2,-1))\n",
    "messages_len_pairs = messages_len[idx].reshape((n_pairs,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaec1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def compute_language_similarity(messages_1 : th.Tensor,\n",
    "                                messages_2 : th.Tensor,\n",
    "                                len_messages_1 : th.Tensor = None,\n",
    "                                len_messages_2 : th.Tensor = None) -> th.Tensor:\n",
    "\n",
    "    distances = []\n",
    "    for i in range(len(messages_1)):\n",
    "        m_1 = messages_1[i]\n",
    "        m_2 = messages_2[i]\n",
    "        len_m_1 = len_messages_1[i]\n",
    "        len_m_2 = len_messages_2[i]\n",
    "        distances.append(editdistance.eval(m_1[:len_m_1],m_2[:len_m_2])/max(len_m_1,len_m_2))\n",
    "\n",
    "    similarity = 1 - th.Tensor(distances)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "distances_inputs=np.mean(1-1*((inputs_pairs[:,0,:]-inputs_pairs[:,1,:])==0),axis=1)\n",
    "distances_messages = 1 - compute_language_similarity(messages_1=messages_pairs[:, 0, :],\n",
    "                                                                         messages_2=messages_pairs[:, 1, :],\n",
    "                                                                         len_messages_1=messages_len_pairs[:, 0],\n",
    "                                                                         len_messages_2=messages_len_pairs[:, 1])\n",
    "\n",
    "top_sim = spearmanr(distances_inputs, distances_messages).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f27b88b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(messages_pairs)==np.ndarray"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
